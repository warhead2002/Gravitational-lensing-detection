{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ddcf39c",
   "metadata": {},
   "source": [
    "Before running, install required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2102af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\daani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.19.5)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\daani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -equests (c:\\users\\daani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\daani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -equests (c:\\users\\daani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: torchvision in c:\\users\\daani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.14.0)\n",
      "Collecting tensorboardX\n",
      "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
      "     ------------------------------------ 125.4/125.4 kB 822.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: torch==1.13.0 in c:\\users\\daani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchvision) (1.13.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\daani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchvision) (4.4.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\daani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchvision) (9.3.0)\n",
      "Requirement already satisfied: requests in c:\\users\\daani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchvision) (2.26.0)\n",
      "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in c:\\users\\daani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboardX) (3.13.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\daani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX) (58.1.0)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\daani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX) (1.15.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\daani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchvision) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\daani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchvision) (2.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\daani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchvision) (2.0.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\daani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchvision) (1.26.6)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2343 sha256=e2c778d99553f409cc04023270cbecc3c50355fb065d131f92b1021d3076aa78\n",
      "  Stored in directory: c:\\users\\daani\\appdata\\local\\pip\\cache\\wheels\\03\\8b\\6f\\9f13c705de81a6b351b718b3cf917e41ad7c0933c8630d4dd4\n",
      "Successfully built sklearn\n",
      "Installing collected packages: sklearn, tensorboardX\n",
      "Successfully installed sklearn-0.0.post1 tensorboardX-2.5.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\daani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -equests (c:\\users\\daani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\daani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -equests (c:\\users\\daani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\daani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -equests (c:\\users\\daani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\daani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -equests (c:\\users\\daani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\daani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -equests (c:\\users\\daani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\daani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -equests (c:\\users\\daani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.3 -> 22.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install numpy sklearn torchvision tensorboardX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d214cf",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cd7f472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from torchvision import datasets, transforms\n",
    "import urllib\n",
    "import zipfile\n",
    "from tensorboardX import SummaryWriter\n",
    "from datetime import datetime\n",
    "from PIL import ImageFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "473062cd-3021-4a23-8da8-b672740d9007",
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adda4de9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# COMMENT THIS OUT IF YOU USE YOUR OWN DATA.\n",
    "# Download example data into ./data/image-data (4 image files, 2 for \"dog\", 2 for \"cat\").\n",
    "# url = \"https://github.com/jrieke/traingenerator/raw/main/data/fake-image-data.zip\"\n",
    "# zip_path, _ = urllib.request.urlretrieve(url)\n",
    "# with zipfile.ZipFile(zip_path, \"r\") as f:\n",
    "#     f.extractall(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e7e1aa",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b7ee366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT YOUR DATA HERE\n",
    "# Expected format: One folder per class, e.g.\n",
    "# train\n",
    "# --- dogs\n",
    "# |   +-- lassie.jpg\n",
    "# |   +-- komissar-rex.png\n",
    "# --- cats\n",
    "# |   +-- garfield.png\n",
    "# |   +-- smelly-cat.png\n",
    "#\n",
    "# Example: https://github.com/jrieke/traingenerator/tree/main/data/image-data\n",
    "train_data = \"train/\"  # required\n",
    "val_data = \"train/\"    # optional\n",
    "test_data = \"test/\"                # optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1a22863",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Set up logging.\n",
    "experiment_id = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "writer = SummaryWriter(logdir=f\"logs/{experiment_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdb5094",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70f08a0a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Set up scaler.\n",
    "scaler = sklearn.preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "582161bb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def preprocess(data, name):\n",
    "    if data is None:  # val/test can be empty\n",
    "        return None\n",
    "    # Read image files to pytorch dataset (only temporary).\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(28), \n",
    "        transforms.CenterCrop(28), \n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    data = datasets.ImageFolder(data, transform=transform)\n",
    "\n",
    "    # Convert to numpy arrays.\n",
    "    images_shape = (len(data), *data[0][0].shape)\n",
    "    images = np.zeros(images_shape)\n",
    "    labels = np.zeros(len(data))\n",
    "    for i, (image, label) in enumerate(data):\n",
    "        images[i] = image\n",
    "        labels[i] = label\n",
    "    \n",
    "    # Flatten.\n",
    "    images = images.reshape(len(images), -1)\n",
    "\n",
    "    # Scale to mean 0 and std 1.\n",
    "    if name == \"train\":\n",
    "        scaler.fit(images)\n",
    "    images = scaler.transform(images)\n",
    "\n",
    "    # Shuffle train set.\n",
    "    if name == \"train\":\n",
    "        images, labels = sklearn.utils.shuffle(images, labels)\n",
    "\n",
    "    return [images, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa58958f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "processed_train_data = preprocess(train_data, \"train\")\n",
    "processed_val_data = preprocess(val_data, \"val\")\n",
    "processed_test_data = preprocess(test_data, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3aee839",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3090790b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33af1ac5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a9c6828",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def evaluate(data, name):\n",
    "    if data is None:  # val/test can be empty\n",
    "        return\n",
    "\n",
    "    images, labels = data\n",
    "    acc = model.score(images, labels)\n",
    "    print(f\"{name + ':':6} accuracy: {acc}\")\n",
    "    writer.add_scalar(f\"{name}_accuracy\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90758230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train on train_data.\n",
    "model.fit(*processed_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6cb79f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: accuracy: 0.76\n",
      "val:   accuracy: 0.76\n",
      "test:  accuracy: 0.6595744680851063\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on all datasets.\n",
    "evaluate(processed_train_data, \"train\")\n",
    "evaluate(processed_val_data, \"val\")\n",
    "evaluate(processed_test_data, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b54b696-3768-4297-80f2-d008ffa76317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'KNN.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262bbdc0-4aa8-454a-b1a5-978cefae585c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
